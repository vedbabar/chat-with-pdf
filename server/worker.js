// worker.js
import { Worker } from "bullmq";
import { PDFLoader } from "@langchain/community/document_loaders/fs/pdf";
import { QdrantVectorStore } from "@langchain/qdrant";
import { GoogleGenerativeAIEmbeddings } from "@langchain/google-genai";
import { RecursiveCharacterTextSplitter } from "langchain/text_splitter"; // â­ ADDED for chunking
import { PrismaClient } from "@prisma/client";
import "dotenv/config";
import fs from "fs/promises"; // â­ ADDED for local file system (temp file)
import path from "path"; // â­ ADDED for path resolving
import axios from "axios"; // â­ ADDED for downloading files
import os from "os"; // â­ ADDED for temp directory

import http from 'http';

// Create a dummy server to keep Render happy
const requestListener = function (req, res) {
  res.writeHead(200);
  res.end('Worker is running!');
}
const server = http.createServer(requestListener);
server.listen(process.env.PORT || 8080);
console.log("Dummy server listening...");

// -------------------- INITIALIZATION --------------------
const prisma = new PrismaClient();

const GEMINI_EMBEDDING_SIZE = 768;
const QDRANT_COLLECTION = process.env.QDRANT_COLLECTION_NAME || "langchainjs-testing";
const REDIS_CONNECTION_URL = process.env.UPSTASH_REDIS_URL || process.env.REDIS_URL;

const embeddings = new GoogleGenerativeAIEmbeddings({
Â  apiKey: process.env.GOOGLE_API_KEY,
Â  model: "text-embedding-004",
});

// -------------------- WORKER --------------------
const worker = new Worker(
Â  "file-upload-queue",
Â  async (job) => {
Â  Â  console.log(`ğŸ“¥ New Job ${job.id}: Processing...`, job.data);

Â  Â  // â­ CHANGED: Get 'url' and 'publicId' instead of 'path'
Â  Â  const { url, chatId, fileId } = JSON.parse(job.data);

Â  Â  if (!url || !chatId || !fileId) {
Â  Â  Â  throw new Error("url, chatId, or fileId missing in job data");
Â  Â  }

    let tempFilePath = ''; 

Â  Â  try {
Â  Â  Â  // 1ï¸âƒ£ Mark file as PROCESSING
Â  Â  Â  await prisma.file.update({
Â  Â  Â  Â  where: { id: fileId },
Â  Â  Â  Â  data: { status: "PROCESSING" },
Â  Â  Â  });

      // â­ ADDED: 2ï¸âƒ£ Download file from URL to temporary location
      const response = await axios.get(url, {
          responseType: 'arraybuffer', 
          maxContentLength: Infinity,
      });

      // Create a secure temporary file path
      const tempDir = os.tmpdir();
      tempFilePath = path.join(tempDir, `docuchat_${fileId}_${Date.now()}.pdf`);
      await fs.writeFile(tempFilePath, response.data);
      console.log(`â¬‡ï¸ File downloaded to temporary path: ${tempFilePath}`);
      
Â  Â  Â  // 3ï¸âƒ£ Load PDF (using the tempFilePath)
Â  Â  Â  const normalizedPath = tempFilePath.replace(/\\/g, "/");
Â  Â  Â  const loader = new PDFLoader(normalizedPath);
Â  Â  Â  const docs = await loader.load();
Â  Â  Â  
Â  Â  Â  // 4ï¸âƒ£ Split documents into smaller chunks
Â  Â  Â  const splitter = new RecursiveCharacterTextSplitter({
Â  Â  Â  Â  chunkSize: 1000,
Â  Â  Â  Â  chunkOverlap: 200,
Â  Â  Â  });
Â  Â  Â  const splitDocs = await splitter.splitDocuments(docs);
Â  Â  Â  console.log(`ğŸ“„ Loaded and split into ${splitDocs.length} chunks for file ${fileId}`);

Â  Â  Â  // 5ï¸âƒ£ Add metadata
Â  Â  Â  const docsWithMetadata = splitDocs.map((doc) => ({
Â  Â  Â  Â  ...doc,
Â  Â  Â  Â  metadata: {
Â  Â  Â  Â  Â  ...doc.metadata,
Â  Â  Â  Â  Â  chatId,
Â  Â  Â  Â  Â  fileId,
Â  Â  Â  Â  },
Â  Â  Â  }));

Â  Â  Â  // 6ï¸âƒ£ Upload vectors
Â  Â  Â  await QdrantVectorStore.fromDocuments(docsWithMetadata, embeddings, {
Â  Â  Â  Â  url: process.env.QDRANT_URL,
Â  Â  Â  Â  apiKey: process.env.QDRANT_API_KEY,
Â  Â  Â  Â  collectionName: QDRANT_COLLECTION,

Â  Â  Â  Â  collectionConfig: {
Â  Â  Â  Â  Â  vectors: {
Â  Â  Â  Â  Â  Â  size: GEMINI_EMBEDDING_SIZE, 
Â  Â  Â  Â  Â  Â  distance: "Cosine",
Â  Â  Â  Â  Â  },
Â  Â  Â  Â  Â  params: {
Â  Â  Â  Â  Â  Â  indexed: [
Â  Â  Â  Â  Â  Â  Â  { field_name: "metadata.chatId", field_type: "keyword" },
Â  Â  Â  Â  Â  Â  Â  { field_name: "metadata.fileId", field_type: "keyword" }
Â  Â  Â  Â  Â  Â  ],
Â  Â  Â  Â  Â  },
Â  Â  Â  Â  }
Â  Â  Â  });

Â  Â  Â  console.log(`âœ… Successfully embedded file ${fileId}`);

Â  Â  Â  // 7ï¸âƒ£ Mark file as DONE
Â  Â  Â  await prisma.file.update({
Â  Â  Â  Â  where: { id: fileId },
Â  Â  Â  Â  data: { status: "DONE" },
Â  Â  Â  });
Â  Â  Â  console.log(`ğŸ“Š Status updated to DONE for file ${fileId}`);

Â  Â  } catch (error) {
Â  Â  Â  console.error(`âŒ Error in job ${job.id}:`, error);

Â  Â  Â  await prisma.file.update({
Â  Â  Â  Â  where: { id: fileId },
Â  Â  Â  Â  data: { status: "ERROR" },
Â  Â  Â  });

Â  Â  Â  throw error;
Â  Â  } finally {
        // â­ CLEANUP: Delete temporary file regardless of success or failure
        if (tempFilePath) {
            try {
                await fs.unlink(tempFilePath);
                console.log(`ğŸ—‘ï¸ Cleaned up temporary file: ${tempFilePath}`);
            } catch (cleanupError) {
                console.warn(`âš ï¸ Failed to clean up temp file ${tempFilePath}:`, cleanupError.message);
            }
        }
    }
Â  },
Â  {
Â  Â  concurrency: 5,
Â  Â  connection: {
Â  Â  Â  url: REDIS_CONNECTION_URL, 
Â  Â  },
Â  Â  removeOnComplete: { count: 100 },
Â  Â  removeOnFail: { count: 50 },
Â  }
);

// -------------------- WORKER EVENTS --------------------
worker.on("completed", (job) => {
Â  console.log(`ğŸ‰ Job ${job.id} completed successfully.`);
});

worker.on("failed", (job, err) => {
Â  console.error(`âŒ Job ${job.id} failed: ${err.message}`);
});

worker.on("error", (err) => {
Â  console.error("âŒ Worker error:", err);
});

console.log("ğŸš€ Worker started and connected to Redis...");